{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Improved Plant Disease Detection Model\\n\",\n",
    "    \"\\n\",\n",
    "    \"This notebook implements several improvements to the existing model architecture:\\n\",\n",
    "    \"1. Increased image resolution from 32x32 to 224x224\\n\",\n",
    "    \"2. Aggressive data augmentation to improve model robustness\\n\",\n",
    "    \"3. Transfer learning using pre-trained models (EfficientNetB0, MobileNetV2, ResNet50)\\n\",\n",
    "    \"4. Experimentation with different optimizers and learning rates\\n\",\n",
    "    \"5. Model quantization for faster inference\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Import necessary libraries\\n\",\n",
    "    \"import tensorflow as tf\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"import seaborn as sns\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import json\\n\",\n",
    "    \"import os\\n\",\n",
    "    \"from tensorflow.keras.applications import EfficientNetB0, MobileNetV2, ResNet50\\n\",\n",
    "    \"from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\\n\",\n",
    "    \"from tensorflow.keras.models import Model\\n\",\n",
    "    \"from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\\n\",\n",
    "    \"from tensorflow.keras.optimizers import Adam, RMSprop\\n\",\n",
    "    \"from tensorflow.keras.preprocessing.image import ImageDataGenerator\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Check for GPU availability\\n\",\n",
    "    \"print(tf.config.list_physical_devices('GPU'))\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 1. Increased Image Resolution and Data Augmentation\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Constants for the image size and batch size\\n\",\n",
    "    \"IMG_SIZE = 224  # Using 224x224 which is standard for many pre-trained models\\n\",\n",
    "    \"BATCH_SIZE = 32  # We can adjust based on available memory\\n\",\n",
    "    \"NUM_CLASSES = 38  # From the existing dataset\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Setup data augmentation for training\\n\",\n",
    "    \"train_datagen = ImageDataGenerator(\\n\",\n",
    "    \"    rescale=1./255,\\n\",\n",
    "    \"    rotation_range=40,       # Rotate images by up to 40 degrees\\n\",\n",
    "    \"    width_shift_range=0.2,   # Shift images horizontally by up to 20% \\n\",\n",
    "    \"    height_shift_range=0.2,  # Shift images vertically by up to 20%\\n\",\n",
    "    \"    shear_range=0.2,         # Shear transformations\\n\",\n",
    "    \"    zoom_range=0.2,          # Zoom in by up to 20%\\n\",\n",
    "    \"    horizontal_flip=True,    # Randomly flip images horizontally\\n\",\n",
    "    \"    vertical_flip=False,     # Plant images typically have orientation (up vs down)\\n\",\n",
    "    \"    fill_mode='nearest',     # Fill in newly created pixels\\n\",\n",
    "    \"    brightness_range=[0.7, 1.3]  # Adjust brightness by up to 30%\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Only rescale validation data - no augmentation for validation\\n\",\n",
    "    \"valid_datagen = ImageDataGenerator(rescale=1./255)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Create data generators that load and preprocess images from directories\\n\",\n",
    "    \"train_generator = train_datagen.flow_from_directory(\\n\",\n",
    "    \"    'train',\\n\",\n",
    "    \"    target_size=(IMG_SIZE, IMG_SIZE),\\n\",\n",
    "    \"    batch_size=BATCH_SIZE,\\n\",\n",
    "    \"    class_mode='categorical',\\n\",\n",
    "    \"    shuffle=True,\\n\",\n",
    "    \"    seed=42\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"validation_generator = valid_datagen.flow_from_directory(\\n\",\n",
    "    \"    'valid',\\n\",\n",
    "    \"    target_size=(IMG_SIZE, IMG_SIZE),\\n\",\n",
    "    \"    batch_size=BATCH_SIZE,\\n\",\n",
    "    \"    class_mode='categorical',\\n\",\n",
    "    \"    shuffle=False\\n\",\n",
    "    \")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 2. Visualize Some Augmented Images\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Function to visualize the augmented images\\n\",\n",
    "    \"def visualize_augmented_images(generator, num_images=5):\\n\",\n",
    "    \"    # Get a batch of images\\n\",\n",
    "    \"    data_batch, label_batch = next(generator)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    plt.figure(figsize=(15, 5 * num_images))\\n\",\n",
    "    \"    for i in range(num_images):\\n\",\n",
    "    \"        plt.subplot(num_images, 5, i*5 + 1)\\n\",\n",
    "    \"        plt.imshow(data_batch[i])\\n\",\n",
    "    \"        plt.title(f\\\"Original {np.argmax(label_batch[i])}\\\")\\n\",\n",
    "    \"        plt.axis('off')\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Generate 4 different augmentations\\n\",\n",
    "    \"        for j in range(4):\\n\",\n",
    "    \"            augmented = train_datagen.random_transform(data_batch[i])\\n\",\n",
    "    \"            plt.subplot(num_images, 5, i*5 + j + 2)\\n\",\n",
    "    \"            plt.imshow(augmented)\\n\",\n",
    "    \"            plt.title(f\\\"Aug {j+1}\\\")\\n\",\n",
    "    \"            plt.axis('off')\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    plt.tight_layout()\\n\",\n",
    "    \"    plt.show()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Visualize augmented images\\n\",\n",
    "    \"visualize_augmented_images(train_generator)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 3. Transfer Learning with Pre-trained Models\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Function to create a model using transfer learning\\n\",\n",
    "    \"def create_transfer_learning_model(base_model_name, trainable=False):\\n\",\n",
    "    \"    # Choose the base model\\n\",\n",
    "    \"    if base_model_name == 'EfficientNetB0':\\n\",\n",
    "    \"        base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\\n\",\n",
    "    \"    elif base_model_name == 'MobileNetV2':\\n\",\n",
    "    \"        base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\\n\",\n",
    "    \"    elif base_model_name == 'ResNet50':\\n\",\n",
    "    \"        base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\\n\",\n",
    "    \"    else:\\n\",\n",
    "    \"        raise ValueError(f\\\"Unknown base model: {base_model_name}\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Freeze the base model if not trainable\\n\",\n",
    "    \"    base_model.trainable = trainable\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Build the model on top of the base model\\n\",\n",
    "    \"    x = base_model.output\\n\",\n",
    "    \"    x = GlobalAveragePooling2D()(x)\\n\",\n",
    "    \"    x = Dense(1024, activation='relu')(x)\\n\",\n",
    "    \"    x = Dropout(0.5)(x)\\n\",\n",
    "    \"    predictions = Dense(NUM_CLASSES, activation='softmax')(x)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Create the model\\n\",\n",
    "    \"    model = Model(inputs=base_model.input, outputs=predictions)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    return model\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Define callbacks for training\\n\",\n",
    "    \"def get_callbacks(model_name):\\n\",\n",
    "    \"    model_checkpoint = ModelCheckpoint(\\n\",\n",
    "    \"        f\\\"{model_name}_plant_disease_model.keras\\\",\\n\",\n",
    "    \"        monitor='val_accuracy',\\n\",\n",
    "    \"        save_best_only=True,\\n\",\n",
    "    \"        mode='max',\\n\",\n",
    "    \"        verbose=1\\n\",\n",
    "    \"    )\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    early_stopping = EarlyStopping(\\n\",\n",
    "    \"        monitor='val_loss',\\n\",\n",
    "    \"        patience=10,\\n\",\n",
    "    \"        restore_best_weights=True,\\n\",\n",
    "    \"        verbose=1\\n\",\n",
    "    \"    )\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    reduce_lr = ReduceLROnPlateau(\\n\",\n",
    "    \"        monitor='val_loss',\\n\",\n",
    "    \"        factor=0.2,\\n\",\n",
    "    \"        patience=5,\\n\",\n",
    "    \"        min_lr=1e-6,\\n\",\n",
    "    \"        verbose=1\\n\",\n",
    "    \"    )\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    return [model_checkpoint, early_stopping, reduce_lr]\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 4. Train Models with Different Architectures and Optimizers\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Function to train a model with various optimizers\\n\",\n",
    "    \"def train_model(model_name, optimizer_name, learning_rate=0.001, epochs=30, fine_tune=False):\\n\",\n",
    "    \"    model = create_transfer_learning_model(model_name, trainable=False)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Define the optimizer\\n\",\n",
    "    \"    if optimizer_name == 'Adam':\\n\",\n",
    "    \"        optimizer = Adam(learning_rate=learning_rate)\\n\",\n",
    "    \"    elif optimizer_name == 'RMSprop':\\n\",\n",
    "    \"        optimizer = RMSprop(learning_rate=learning_rate)\\n\",\n",
    "    \"    else:\\n\",\n",
    "    \"        raise ValueError(f\\\"Unknown optimizer: {optimizer_name}\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Compile the model\\n\",\n",
    "    \"    model.compile(\\n\",\n",
    "    \"        optimizer=optimizer,\\n\",\n",
    "    \"        loss='categorical_crossentropy',\\n\",\n",
    "    \"        metrics=['accuracy']\\n\",\n",
    "    \"    )\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Get callbacks\\n\",\n",
    "    \"    callbacks = get_callbacks(f\\\"{model_name}_{optimizer_name}_lr{learning_rate}\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Train the model\\n\",\n",
    "    \"    print(f\\\"Training {model_name} with {optimizer_name} optimizer and learning rate {learning_rate}\\\")\\n\",\n",
    "    \"    history = model.fit(\\n\",\n",
    "    \"        train_generator,\\n\",\n",
    "    \"        epochs=epochs,\\n\",\n",
    "    \"        validation_data=validation_generator,\\n\",\n",
    "    \"        callbacks=callbacks,\\n\",\n",
    "    \"        verbose=1\\n\",\n",
    "    \"    )\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Fine-tune if requested\\n\",\n",
    "    \"    if fine_tune:\\n\",\n",
    "    \"        print(f\\\"Fine-tuning {model_name}...\\\")\\n\",\n",
    "    \"        # Unfreeze the top layers of the base model\\n\",\n",
    "    \"        for layer in model.layers[0].layers[-20:]:  # Unfreeze the last 20 layers\\n\",\n",
    "    \"            layer.trainable = True\\n\",\n",
    "    \"            \\n\",\n",
    "    \"        # Recompile with a lower learning rate\\n\",\n",
    "    \"        if optimizer_name == 'Adam':\\n\",\n",
    "    \"            optimizer = Adam(learning_rate=learning_rate/10)\\n\",\n",
    "    \"        else:\\n\",\n",
    "    \"            optimizer = RMSprop(learning_rate=learning_rate/10)\\n\",\n",
    "    \"            \\n\",\n",
    "    \"        model.compile(\\n\",\n",
    "    \"            optimizer=optimizer,\\n\",\n",
    "    \"            loss='categorical_crossentropy',\\n\",\n",
    "    \"            metrics=['accuracy']\\n\",\n",
    "    \"        )\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Update callbacks for fine-tuning\\n\",\n",
    "    \"        callbacks = get_callbacks(f\\\"{model_name}_{optimizer_name}_lr{learning_rate}_finetuned\\\")\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Continue training\\n\",\n",
    "    \"        history_fine = model.fit(\\n\",\n",
    "    \"            train_generator,\\n\",\n",
    "    \"            epochs=epochs//2,  # Fewer epochs for fine-tuning\\n\",\n",
    "    \"            validation_data=validation_generator,\\n\",\n",
    "    \"            callbacks=callbacks,\\n\",\n",
    "    \"            verbose=1\\n\",\n",
    "    \"        )\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Combine the histories\\n\",\n",
    "    \"        for k in history_fine.history:\\n\",\n",
    "    \"            history.history[k].extend(history_fine.history[k])\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Save the training history\\n\",\n",
    "    \"    with open(f\\\"{model_name}_{optimizer_name}_lr{learning_rate}_history.json\\\", 'w') as f:\\n\",\n",
    "    \"        json.dump(history.history, f)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    return model, history\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Define the experiments to run\\n\",\n",
    "    \"experiments = [\\n\",\n",
    "    \"    {'model': 'EfficientNetB0', 'optimizer': 'Adam', 'lr': 0.001, 'fine_tune': True},\\n\",\n",
    "    \"    {'model': 'MobileNetV2', 'optimizer': 'Adam', 'lr': 0.001, 'fine_tune': True},\\n\",\n",
    "    \"    {'model': 'ResNet50', 'optimizer': 'Adam', 'lr': 0.001, 'fine_tune': True},\\n\",\n",
    "    \"    # Testing different optimizers on the best model\\n\",\n",
    "    \"    {'model': 'EfficientNetB0', 'optimizer': 'RMSprop', 'lr': 0.001, 'fine_tune': True},\\n\",\n",
    "    \"    # Testing different learning rates\\n\",\n",
    "    \"    {'model': 'EfficientNetB0', 'optimizer': 'Adam', 'lr': 0.0001, 'fine_tune': True},\\n\",\n",
    "    \"]\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Run experiments (commented out to prevent accidental execution)\\n\",\n",
    "    \"# Uncomment to run the experiments\\n\",\n",
    "    \"\\n\",\n",
    "    \"# results = {}\\n\",\n",
    "    \"# for exp in experiments:\\n\",\n",
    "    \"#     model, history = train_model(\\n\",\n",
    "    \"#         model_name=exp['model'],\\n\",\n",
    "    \"#         optimizer_name=exp['optimizer'],\\n\",\n",
    "    \"#         learning_rate=exp['lr'],\\n\",\n",
    "    \"#         fine_tune=exp['fine_tune']\\n\",\n",
    "    \"#     )\\n\",\n",
    "    \"#     results[f\\\"{exp['model']}_{exp['optimizer']}_lr{exp['lr']}\\\"] = {\\n\",\n",
    "    \"#         'val_accuracy': max(history.history['val_accuracy']),\\n\",\n",
    "    \"#         'val_loss': min(history.history['val_loss'])\\n\",\n",
    "    \"#     }\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 5. Model Evaluation\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Function to plot training history\\n\",\n",
    "    \"def plot_training_history(history):\\n\",\n",
    "    \"    # Plot training & validation accuracy values\\n\",\n",
    "    \"    plt.figure(figsize=(12, 4))\\n\",\n",
    "    \"    plt.subplot(1, 2, 1)\\n\",\n",
    "    \"    plt.plot(history.history['accuracy'])\\n\",\n",
    "    \"    plt.plot(history.history['val_accuracy'])\\n\",\n",
    "    \"    plt.title('Model accuracy')\\n\",\n",
    "    \"    plt.ylabel('Accuracy')\\n\",\n",
    "    \"    plt.xlabel('Epoch')\\n\",\n",
    "    \"    plt.legend(['Train', 'Validation'], loc='upper left')\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Plot training & validation loss values\\n\",\n",
    "    \"    plt.subplot(1, 2, 2)\\n\",\n",
    "    \"    plt.plot(history.history['loss'])\\n\",\n",
    "    \"    plt.plot(history.history['val_loss'])\\n\",\n",
    "    \"    plt.title('Model loss')\\n\",\n",
    "    \"    plt.ylabel('Loss')\\n\",\n",
    "    \"    plt.xlabel('Epoch')\\n\",\n",
    "    \"    plt.legend(['Train', 'Validation'], loc='upper left')\\n\",\n",
    "    \"    plt.tight_layout()\\n\",\n",
    "    \"    plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Load a trained model (choose the best one based on validation accuracy)\\n\",\n",
    "    \"# model = tf.keras.models.load_model('EfficientNetB0_Adam_lr0.001_finetuned_plant_disease_model.keras')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# # Evaluate the model on validation data\\n\",\n",
    "    \"# evaluation = model.evaluate(validation_generator)\\n\",\n",
    "    \"# print(f\\\"Validation Loss: {evaluation[0]:.4f}\\\")\\n\",\n",
    "    \"# print(f\\\"Validation Accuracy: {evaluation[1]:.4f}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 6. Model Quantization for Faster Inference\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Function to apply TFLite quantization\\n\",\n",
    "    \"def quantize_model(model, model_name):\\n\",\n",
    "    \"    # Convert the model to TFLite\\n\",\n",
    "    \"    converter = tf.lite.TFLiteConverter.from_keras_model(model)\\n\",\n",
    "    \"    tflite_model = converter.convert()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Save the TFLite model\\n\",\n",
    "    \"    with open(f\\\"{model_name}_quantized.tflite\\\", 'wb') as f:\\n\",\n",
    "    \"        f.write(tflite_model)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Also try with quantization\\n\",\n",
    "    \"    converter = tf.lite.TFLiteConverter.from_keras_model(model)\\n\",\n",
    "    \"    converter.optimizations = [tf.lite.Optimize.DEFAULT]\\n\",\n",
    "    \"    quantized_tflite_model = converter.convert()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Save the quantized TFLite model\\n\",\n",
    "    \"    with open(f\\\"{model_name}_quantized_optimized.tflite\\\", 'wb') as f:\\n\",\n",
    "    \"        f.write(quantized_tflite_model)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"    # Print model sizes\\n\",\n",
    "    \"    print(f\\\"Original TFLite model size: {len(tflite_model) / 1024 / 1024:.2f} MB\\\")\\n\",\n",
    "    \"    print(f\\\"Quantized TFLite model size: {len(quantized_tflite_model) / 1024 / 1024:.2f} MB\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    return tflite_model, quantized_tflite_model\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Apply quantization to the best model\\n\",\n",
    "    \"# tflite_model, quantized_tflite_model = quantize_model(model, 'EfficientNetB0_Adam_lr0.001_finetuned')\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 7. Update the Prediction Function for the New Model\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Function to make predictions using the improved model\\n\",\n",
    "    \"def improved_model_prediction(test_image_path, model_path='EfficientNetB0_Adam_lr0.001_finetuned_plant_disease_model.keras'):\\n\",\n",
    "    \"    # Load the model\\n\",\n",
    "    \"    model = tf.keras.models.load_model(model_path)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Load and preprocess the image\\n\",\n",
    "    \"    img = tf.keras.preprocessing.image.load_img(test_image_path, target_size=(IMG_SIZE, IMG_SIZE))\\n\",\n",
    "    \"    img_array = tf.keras.preprocessing.image.img_to_array(img)\\n\",\n",
    "    \"    img_array = img_array / 255.0  # Normalize pixel values\\n\",\n",
    "    \"    img_array = np.expand_dims(img_array, axis=0)  # Create batch dimension\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Make prediction\\n\",\n",
    "    \"    predictions = model.predict(img_array)\\n\",\n",
    "    \"    class_index = np.argmax(predictions, axis=1)[0]\\n\",\n",
    "    \"    confidence = predictions[0][class_index]\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Get class names from validation generator\\n\",\n",
    "    \"    class_names = validation_generator.class_indices\\n\",\n",
    "    \"    class_names = {v: k for k, v in class_names.items()}\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    predicted_class = class_names[class_index]\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    return predicted_class, confidence\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 8. Testing the Improved Model\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Test the improved model on sample images\\n\",\n",
    "    \"def test_model_on_samples(model_path, test_dir='test'):\\n\",\n",
    "    \"    # Get a list of test images\\n\",\n",
    "    \"    test_images = [os.path.join(test_dir, f) for f in os.listdir(test_dir) if f.endswith(('.JPG', '.jpg', '.png'))]\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Display results for a few images\\n\",\n",
    "    \"    plt.figure(figsize=(15, 15))\\n\",\n",
    "    \"    for i, img_path in enumerate(test_images[:9]):  # Display up to 9 images\\n\",\n",
    "    \"        # Make prediction\\n\",\n",
    "    \"        predicted_class, confidence = improved_model_prediction(img_path, model_path)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Load and display image\\n\",\n",
    "    \"        img = tf.keras.preprocessing.image.load_img(img_path, target_size=(IMG_SIZE, IMG_SIZE))\\n\",\n",
    "    \"        plt.subplot(3, 3, i+1)\\n\",\n",
    "    \"        plt.imshow(img)\\n\",\n",
    "    \"        plt.title(f\\\"{os.path.basename(img_path)}\\\\nPredicted: {predicted_class}\\\\nConfidence: {confidence:.2f}\\\")\\n\",\n",
    "    \"        plt.axis('off')\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    plt.tight_layout()\\n\",\n",
    "    \"    plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Test the model on sample images (uncomment to run after training)\\n\",\n",
    "    \"# test_model_on_samples('EfficientNetB0_Adam_lr0.001_finetuned_plant_disease_model.keras')\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 9. Update main.py to use the improved model\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Code to update main.py\\n\",\n",
    "    \"# This code won't be executed here, but should be added to main.py\\n\",\n",
    "    \"\\n\",\n",
    "    \"'''\\n\",\n",
    "    \"# TensorFlow Model Prediction Function\\n\",\n",
    "    \"def model_prediction(test_image):\\n\",\n",
    "    \"    model = tf.keras.models.load_model(\\\"EfficientNetB0_Adam_lr0.001_finetuned_plant_disease_model.keras\\\")\\n\",\n",
    "    \"    image = tf.keras.preprocessing.image.load_img(test_image, target_size=(224, 224))\\n\",\n",
    "    \"    input_arr = tf.keras.preprocessing.image.img_to_array(image)\\n\",\n",
    "    \"    input_arr = input_arr / 255.0  # Normalize pixel values\\n\",\n",
    "    \"    input_arr = np.array([input_arr])  # Convert single image to batch\\n\",\n",
    "    \"    predictions = model.predict(input_arr)\\n\",\n",
    "    \"    return np.argmax(predictions)  # Return index of max element\\n\",\n",
    "    \"'''\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.8.10\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
